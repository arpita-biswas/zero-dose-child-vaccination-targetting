{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pal = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['countrywave', 'caseid', 'midx', 'dhsid', 'v000', 'v001', 'v002',\n",
      "       'v003', 'v007', 'v024', 'ch_allvac_either', 'ch_allvac_moth',\n",
      "       'ch_allvac_card', 'ch_novac_either', 'ch_novac_moth', 'ch_novac_card',\n",
      "       'age', 'male', 'birth_order', 'mum_educlow', 'mum_educhigher',\n",
      "       'npregnancies', 'firstpreg', 'hh_5plus', 'hh_urban', 'hh_wealth',\n",
      "       'anc_any', 'anc_number', 'facdelivery', 'regionname_original',\n",
      "       'IA2015district', 'ia2015fic', 'IA2020district',\n",
      "       'v024_states_asin_IA202020', 'geo_ia2015', 'dhs_ipumsi_ia',\n",
      "       'dhs_ipumsi_ml', 'dhs_ipumsi_ng', 'regionname', 'gps_dataset', 'dhscc',\n",
      "       'dhsyear', 'dhsclust', 'surveyid', 'all_population_count_2015',\n",
      "       'nightlights_composite', 'travel_times_2015', 'u5_population_2015',\n",
      "       'un_population_count_2015', 'un_population_density_2015', 'urban_rura',\n",
      "       'latnum', 'longnum', 'datum', 'clusterid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Read the raw data from .dta file\n",
    "data_dta = pd.io.stata.read_stata('../Data/ZDinputdata_Jan23.dta')\n",
    "#print(data_dta.head())\n",
    "print(data_dta.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['countrywave', 'caseid', 'midx', 'dhsid', 'v000', 'v001', 'v002',\n",
      "       'v003', 'v007', 'v024', 'ch_allvac_either', 'ch_allvac_moth',\n",
      "       'ch_allvac_card', 'any_vac', 'ch_novac_moth', 'ch_novac_card', 'age',\n",
      "       'male', 'birth_order', 'mum_educlow', 'mum_educhigher', 'npregnancies',\n",
      "       'firstpreg', 'hh_5plus', 'hh_urban', 'hh_wealth', 'anc_any',\n",
      "       'anc_number', 'facdelivery', 'regionname_original', 'IA2015district',\n",
      "       'ia2015fic', 'IA2020district', 'v024_states_asin_IA202020',\n",
      "       'geo_ia2015', 'dhs_ipumsi_ia', 'dhs_ipumsi_ml', 'dhs_ipumsi_ng',\n",
      "       'regionname', 'gps_dataset', 'dhscc', 'dhsyear', 'dhsclust', 'surveyid',\n",
      "       'all_population_count_2015', 'nightlights_composite',\n",
      "       'travel_times_2015', 'u5_population_2015', 'un_population_count_2015',\n",
      "       'un_population_density_2015', 'urban_rura', 'latnum', 'longnum',\n",
      "       'datum', 'clusterid', 'all_vac', 'anc_cat', 'age_group',\n",
      "       'un_population_cat', 'sdist'],\n",
      "      dtype='object')\n",
      "46209\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing!\n",
    "#https://dhsprogram.com/pubs/pdf/DHSG4/Recode7_DHS_10Sep2018_DHSG4.pdf (Description)\n",
    "\n",
    "\n",
    "#create label any_vac: 1 means at least one vaccine obtained and 0 means no vaccine\n",
    "data = data_dta.rename(columns={\"ch_novac_either\": \"any_vac\"})\n",
    "data[\"any_vac\"] = data[\"any_vac\"].replace({0:1, 1:0})\n",
    "data['all_vac'] = data['ch_allvac_either']\n",
    "\n",
    "#convert anc_number to categories\n",
    "data['anc_number'] = data[\"anc_number\"].replace(\"no antenatal visits\", 0)\n",
    "bins= [0, 1, 4, 100]\n",
    "labels = ['no','low','high']\n",
    "data['anc_cat'] = pd.cut(data['anc_number'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "#convert age to categories\n",
    "bins= [12,15,18,21,24]\n",
    "labels = ['12-14','15-17','18-20','21-24']\n",
    "data['age_group'] = pd.cut(data['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "#replace na with -1 for population density\n",
    "data['un_population_count_2015'] = data['un_population_density_2015'].fillna(-1)\n",
    "#categorize population into (<300, 300-1500, 1500+)\n",
    "bins= [-1, 0, 300, 1500, max(data['un_population_count_2015'])]\n",
    "labels = ['NA','Village','Town','City']\n",
    "data['un_population_cat'] = pd.cut(data['un_population_count_2015'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "#create a district code variable for IA 2015 and IA 2020\n",
    "data['sdist'] = data['IA2015district'].fillna(data['IA2020district'])\n",
    "\n",
    "sparse_predictors = [\"age_group\", \"male\", \"anc_cat\", \"facdelivery\", \"hh_urban\", \"v024\"] #administrative data\n",
    "contextual_predictors = [\"nightlights_composite\", \"un_population_cat\", \"travel_times_2015\"] #custer level data from censor\n",
    "additional_predictors = [\"birth_order\", \"mum_educlow\", \"mum_educhigher\",\n",
    "                        \"npregnancies\", \"firstpreg\", \"hh_5plus\", \"hh_wealth\"]# survey data\n",
    "                        #hh_plus5= #family_members>5\n",
    "\n",
    "extra_features = ['sdist', 'regionname', 'clusterid', 'ia2015fic', 'all_vac']\n",
    "\n",
    "contextual_datasets = ['IA2020', 'IA2015','ML2018','NG2018']\n",
    "print(data.columns)\n",
    "print(data[data['countrywave']=='IA2015'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['any_vac', 'countrywave', 'age_group', 'male', 'anc_cat', 'facdelivery',\n",
      "       'hh_urban', 'v024', 'birth_order', 'mum_educlow', 'mum_educhigher',\n",
      "       'npregnancies', 'firstpreg', 'hh_5plus', 'hh_wealth',\n",
      "       'nightlights_composite', 'un_population_cat', 'travel_times_2015',\n",
      "       'sdist', 'regionname', 'clusterid', 'ia2015fic', 'all_vac'],\n",
      "      dtype='object')\n",
      "(107024, 23)\n",
      "46209\n"
     ]
    }
   ],
   "source": [
    "data_reduced= data[[\"any_vac\", 'countrywave'] + sparse_predictors + additional_predictors + contextual_predictors + extra_features]\n",
    "print(data_reduced.columns)\n",
    "print(data_reduced.shape)\n",
    "print(data_reduced[data_reduced['countrywave']=='IA2015'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML2018\n",
      "NG2018\n",
      "ML2006\n",
      "IA2006\n",
      "NG2008\n",
      "IA2015\n",
      "IA2020\n",
      "clean CSV files created\n"
     ]
    }
   ],
   "source": [
    "#split data into multiple countries; also categorize nighttime light into 11 bins\n",
    "import statistics as s\n",
    "countries = [\"ML2018\", \"NG2018\", \"ML2006\", \"IA2006\",  \"NG2008\", \"IA2015\", \"IA2020\"]\n",
    "for country in countries:\n",
    "    df = data_reduced[data_reduced['countrywave']==country]\n",
    "    #df['nightlights_composite'].fillna(0, inplace=True) #replacing nightlight 'na' with 0\n",
    "    #df.dropna(inplace=True)\n",
    "    print(country)\n",
    "    if(country in contextual_datasets):\n",
    "        df = df[df['nightlights_composite'].notnull()] # Removed all the rows with no nightlight information\n",
    "        x = df['nightlights_composite']\n",
    "        #print(x.unique())\n",
    "        x = x[x>0]\n",
    "        min_x = min(x)\n",
    "        max_x = max(x)+1 \n",
    "        deciles = s.quantiles(x, n=10)\n",
    "        deciles = [0, min_x]+deciles + [max_x]\n",
    "        labels = ['zero','first','second','third', 'fourth', 'fifth', 'sixth', 'seventh', 'eight', 'nineth', 'tenth']\n",
    "        df['nightlights_composite'] = (pd.cut(df['nightlights_composite'], bins=deciles, labels=labels, right=False))\n",
    "        if(country not in ['IA2020', 'IA2015']):\n",
    "             df = df.drop(['sdist'], axis=1)\n",
    "        if(country in ['IA2015']):\n",
    "            df['IMI_target'] = (df['ia2015fic']<0.8).astype(int)\n",
    "        else:\n",
    "            df = df.drop(['ia2015fic'], axis=1)\n",
    "    else:\n",
    "        df = df.drop(['sdist', 'ia2015fic']+contextual_predictors, axis=1)    \n",
    "\n",
    "    df = df.drop('countrywave', axis=1)\n",
    "    df.to_csv('../data/clean_data/'+country+'.csv', index=False)\n",
    "print('clean CSV files created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utility functions\n",
    "categorical_predictors = ['age_group', 'anc_cat', 'un_population_cat', 'nightlights_composite', 'v024', 'clusterid', 'hh_wealth']\n",
    "\n",
    "#Read file from CSV and return a dataframe\n",
    "def read_file(country, verbose = False):\n",
    "    df = (pd.read_csv('../data/clean_data/' + country + \".csv\"))\n",
    "    for feature in categorical_predictors:\n",
    "        if feature in df.columns:\n",
    "            df[feature] = df[feature].astype('category')\n",
    "    if verbose:\n",
    "        print('Read complete: Clean data for '+country)\n",
    "        print(df.dtypes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing missing values, After removing mising values, difference, fraction of ZD, nv024, nregionnames\n",
      "Country:IA2020, 40555, 40290, 265, 0.037081161578555455, 30, 30\n",
      "Country:IA2015, 46209, 45977, 232, 0.06672901668225417, 30, 30\n",
      "Country:IA2006, 8978, 8978, 0, 0.05981287591891293, 26, 26\n",
      "Country:ML2018, 1803, 1743, 60, 0.1583476764199656, 8, 8\n",
      "Country:ML2006, 2440, 2440, 0, 0.12786885245901636, 8, 8\n",
      "Country:NG2018, 2350, 2292, 58, 0.16099476439790572, 37, 37\n",
      "Country:NG2008, 4689, 4689, 0, 0.2945190872254212, 37, 37\n"
     ]
    }
   ],
   "source": [
    "#Find the number of missing data points\n",
    "countries = [\"IA2020\", \"IA2015\", \"IA2006\", \"ML2018\", \"ML2006\", \"NG2018\", \"NG2008\"]\n",
    "print(\"Before removing missing values, After removing mising values, difference, fraction of ZD, nv024, nregionnames\")\n",
    "for country in countries:\n",
    "    d = read_file(country)\n",
    "    d2 = d.dropna()\n",
    "    d_old = data_reduced[data_reduced['countrywave']==country]\n",
    "    nv024 = d2['v024'].unique().shape[0]\n",
    "    nregions = d2['regionname'].unique().shape[0]\n",
    "    print(\"Country:\"+country+\", \"+str(d_old.shape[0])+\", \"+str(d2.shape[0])+\", \"+str(d_old.shape[0]-d2.shape[0]) + \", \"+str(1-np.mean(d2['any_vac']))+\", \"+str(nv024)+\", \"+ str(nregions))\n",
    "    #Add updated numbers to the draft\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1041=andaman and nicobar islands']\n",
      "['1028=andhra pradesh and telangana']\n",
      "['1012=arunachal pradesh']\n",
      "['1018=assam']\n",
      "['1010=bihar and jharkhand']\n",
      "['1042=chandigarh']\n",
      "['1023=madhya pradesh and chhattisgarh']\n",
      "['1070=goa; dadra and nagar haveli; daman and diu']\n",
      "['1024=gujarat']\n",
      "['1006=haryana']\n",
      "['1002=himachal pradesh']\n",
      "['1001=jammu and kashmir']\n",
      "['1029=karnataka']\n",
      "['1032=kerala']\n",
      "['1044=lakshadweep']\n",
      "['1027=maharashtra']\n",
      "['1014=manipur']\n",
      "['1017=meghalaya']\n",
      "['1015=mizoram']\n",
      "['1013=nagaland']\n",
      "['1007=delhi']\n",
      "['1021=orissa']\n",
      "['1045=pondicherry']\n",
      "['1003=punjab']\n",
      "['1008=rajasthan']\n",
      "['1011=sikkim']\n",
      "['1033=tamil nadu']\n",
      "['1016=tripura']\n",
      "['1009=uttar pradesh and uttaranchal']\n",
      "['1019=west bengal']\n"
     ]
    }
   ],
   "source": [
    "d = read_file('IA2015')\n",
    "d = d.dropna()\n",
    "unique_IDs = (d['v024'].unique())\n",
    "for id in unique_IDs:\n",
    "    print(str(id)+\"=\"+d[d['v024']==id]['regionname'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3d921727fd142f159995321f554abb728fc3b584f7afa5859167818ca059b72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
